{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnitTest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4nDXpUfXE+wY/GSMBk4IA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ria-Chaudhuri/Evaluation/blob/main/UnitTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PreReq- please install the following packages\n",
        "#!pip install apache_beam\n",
        "#!pip install apache-beam[gcp]"
      ],
      "metadata": {
        "id": "TNnXDKnVZ6gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imported Libraries and dependencies\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from datetime import datetime\n",
        "import json\n",
        "from apache_beam.testing.test_pipeline import TestPipeline\n",
        "from apache_beam.testing.util import assert_that\n",
        "from apache_beam.testing.util import equal_to\n",
        "\n",
        "#ParDo Transforms \n",
        "class TransactionAmountGreaterThan20(beam.DoFn):\n",
        "  def process(self, element):\n",
        "     if float(element[3])>20.00:\n",
        "          yield element\n",
        "\n",
        "class ConvertToDateWithTransaction(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    date=datetime.strptime((element[0]), \"%Y-%m-%d %H:%M:%S %Z\").date()\n",
        "    result=[(date.strftime('%Y-%m-%d'),float(element[3]))]\n",
        "    return result\n",
        "\n",
        "#Composite Transform for allplying all the transformation\n",
        "@beam.ptransform_fn\n",
        "def TransactionsWithAllTransforms(pcoll):\n",
        "  return (\n",
        "      pcoll\n",
        "                    | 'Split the File'>>beam.Map(lambda x:x.split(\",\"))\n",
        "                    |'Transactions Greater Than 20  ' >> beam.ParDo(TransactionAmountGreaterThan20())\n",
        "                    | 'Transactions after 2010  ' >> beam.Filter(lambda record: datetime.strptime((record[0]), \"%Y-%m-%d %H:%M:%S %Z\").year >2010)\n",
        "                    | 'Convert To Date With Transactions' >> beam.ParDo(ConvertToDateWithTransaction())\n",
        "                    | 'Sum values per key' >> beam.CombinePerKey(sum)\n",
        "                    | 'FormatOutput' >> beam.Map(json.dumps)\n",
        "         )\n",
        "\n",
        "pipe= beam.Pipeline()\n",
        "\n",
        "with beam.Pipeline(options=PipelineOptions()) as pipeline:\n",
        "  lines = (pipeline | 'ReadMyFile' >> beam.io.ReadFromText('gs://cloud-samples-data/bigquery/sample-transactions/transactions.csv',skip_header_lines=True)\n",
        "                    |  'Apply All the Transforms'>> TransactionsWithAllTransforms()\n",
        "                    |beam.Map(print)\n",
        "                    #|  'Write Output' >> beam.io.WriteToText( file_path_prefix='result.json.gz',header='date, total_amount') \n",
        "  )"
      ],
      "metadata": {
        "id": "YanFvARgUmT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqeUBzqbUe6T"
      },
      "outputs": [],
      "source": [
        "from apache_beam.testing.test_pipeline import TestPipeline\n",
        "from apache_beam.testing.util import assert_that\n",
        "from apache_beam.testing.util import equal_to\n",
        "from apache_beam.dataframe.io import read_csv\n",
        "import unittest\n",
        "\n",
        "\n",
        "class CountTest(unittest.TestCase):\n",
        "\n",
        "  def test_count(self):\n",
        "    # Create a test pipeline.\n",
        "    with TestPipeline() as p:\n",
        "\n",
        "      # Create an input PCollection.\n",
        "      input = p | 'ReadMyFile' >> beam.io.ReadFromText('SampleData.csv',skip_header_lines=True)\n",
        "                 \n",
        "\n",
        "      # Apply the Count transform under test.\n",
        "      output = input | TransactionsWithAllTransforms()\n",
        "                      \n",
        "                          \n",
        "\n",
        "      # Assert on the results.\n",
        "      assert_that(\n",
        "       output,\n",
        "        equal_to([['2018-08-09', '100.99'], ['2019-01-09', '547534.23']]))   \n",
        "            \n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ]
    }
  ]
}